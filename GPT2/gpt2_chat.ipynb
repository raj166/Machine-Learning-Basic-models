{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raj166/Machine-Learning-Basic-models/blob/main/GPT2/gpt2_chat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wsbo8y8iPqsV",
        "outputId": "ea970302-1c98-47a2-baf3-da0636f1ddf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 1.x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noBusm7WIPSu",
        "outputId": "5f16499c-9fe4-469c-91e2-09ab74ba872c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gpt_2_simple in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gpt_2_simple) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from gpt_2_simple) (2019.12.20)\n",
            "Requirement already satisfied: tensorflow>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from gpt_2_simple) (2.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gpt_2_simple) (1.21.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gpt_2_simple) (4.63.0)\n",
            "Requirement already satisfied: toposort in /usr/local/lib/python3.7/dist-packages (from gpt_2_simple) (1.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (1.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (1.44.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (3.17.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (13.0.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (1.14.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (3.10.0.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (3.1.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (0.24.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt_2_simple) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.5.1->gpt_2_simple) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.5.1->gpt_2_simple) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt_2_simple) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt_2_simple) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt_2_simple) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt_2_simple) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt_2_simple) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt_2_simple) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt_2_simple) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt_2_simple) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt_2_simple) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt_2_simple) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt_2_simple) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt_2_simple) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt_2_simple) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gpt_2_simple) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gpt_2_simple) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gpt_2_simple) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gpt_2_simple) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt_2_simple) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gpt_2_simple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZt8DyErPn5j"
      },
      "outputs": [],
      "source": [
        "import gpt_2_simple as gpt2\n",
        "import os\n",
        "import requests\n",
        "\n",
        "model_name = '124M'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiKy4_WSRLi5",
        "outputId": "ef429ba9-d8da-47ef-f381-a14b86bf1ad4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 463Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 4.58Mit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 643Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:11, 43.5Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 338Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 6.17Mit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 6.34Mit/s]\n"
          ]
        }
      ],
      "source": [
        "# if not os.path.isdir(os.path.join(\"models\", model_name)):\n",
        "gpt2.download_gpt2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1IXITPYSOmz"
      },
      "outputs": [],
      "source": [
        "sess = gpt2.start_tf_sess()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQyQW8nkP5Ac",
        "outputId": "3467b2ea-33a3-41fc-cbaf-c8bc447f8ac7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n",
            "Loading dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.16s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset has 240918 tokens\n",
            "Training...\n",
            "[1 | 10.25] loss=2.08 avg=2.08\n",
            "[2 | 14.72] loss=2.10 avg=2.09\n",
            "[3 | 19.17] loss=2.14 avg=2.10\n",
            "[4 | 23.63] loss=2.04 avg=2.09\n",
            "[5 | 28.10] loss=1.89 avg=2.05\n",
            "[6 | 32.58] loss=1.75 avg=2.00\n",
            "[7 | 37.06] loss=1.76 avg=1.96\n",
            "[8 | 41.55] loss=1.69 avg=1.93\n",
            "[9 | 46.04] loss=1.72 avg=1.90\n",
            "[10 | 50.55] loss=1.58 avg=1.87\n",
            "[11 | 55.07] loss=1.59 avg=1.84\n",
            "[12 | 59.60] loss=1.64 avg=1.82\n",
            "[13 | 64.12] loss=1.65 avg=1.81\n",
            "[14 | 68.65] loss=1.51 avg=1.79\n",
            "[15 | 73.18] loss=1.55 avg=1.77\n",
            "[16 | 77.69] loss=1.52 avg=1.75\n",
            "[17 | 82.22] loss=1.55 avg=1.74\n",
            "[18 | 86.74] loss=1.50 avg=1.73\n",
            "[19 | 91.25] loss=1.54 avg=1.71\n",
            "[20 | 95.77] loss=1.42 avg=1.70\n",
            "[21 | 100.28] loss=1.37 avg=1.68\n",
            "[22 | 104.81] loss=1.52 avg=1.67\n",
            "[23 | 109.32] loss=1.67 avg=1.67\n",
            "[24 | 113.84] loss=1.34 avg=1.66\n",
            "[25 | 118.35] loss=1.44 avg=1.65\n",
            "[26 | 122.86] loss=1.39 avg=1.64\n",
            "[27 | 127.38] loss=1.60 avg=1.64\n",
            "[28 | 131.89] loss=1.38 avg=1.62\n",
            "[29 | 136.40] loss=1.48 avg=1.62\n",
            "[30 | 140.92] loss=1.52 avg=1.62\n",
            "[31 | 145.43] loss=1.47 avg=1.61\n",
            "[32 | 149.94] loss=1.43 avg=1.60\n",
            "[33 | 154.45] loss=1.45 avg=1.60\n",
            "[34 | 158.96] loss=1.37 avg=1.59\n",
            "[35 | 163.47] loss=1.37 avg=1.58\n",
            "[36 | 167.97] loss=1.32 avg=1.57\n",
            "[37 | 172.48] loss=1.42 avg=1.57\n",
            "[38 | 176.99] loss=1.48 avg=1.57\n",
            "[39 | 181.50] loss=1.36 avg=1.56\n",
            "[40 | 186.02] loss=1.48 avg=1.56\n",
            "[41 | 190.53] loss=1.34 avg=1.55\n",
            "[42 | 195.03] loss=1.62 avg=1.55\n",
            "[43 | 199.54] loss=1.45 avg=1.55\n",
            "[44 | 204.04] loss=1.37 avg=1.54\n",
            "[45 | 208.55] loss=1.25 avg=1.54\n",
            "[46 | 213.06] loss=1.48 avg=1.53\n",
            "[47 | 217.57] loss=1.42 avg=1.53\n",
            "[48 | 222.07] loss=1.31 avg=1.53\n",
            "[49 | 226.59] loss=1.45 avg=1.52\n",
            "[50 | 231.09] loss=1.22 avg=1.52\n",
            "[51 | 235.60] loss=1.36 avg=1.51\n",
            "[52 | 240.10] loss=1.42 avg=1.51\n",
            "[53 | 244.60] loss=1.28 avg=1.50\n",
            "[54 | 249.11] loss=1.40 avg=1.50\n",
            "[55 | 253.62] loss=1.27 avg=1.50\n",
            "[56 | 258.13] loss=1.37 avg=1.49\n",
            "[57 | 262.65] loss=1.28 avg=1.49\n",
            "[58 | 267.15] loss=1.33 avg=1.49\n",
            "[59 | 271.65] loss=1.33 avg=1.48\n",
            "[60 | 276.15] loss=1.33 avg=1.48\n",
            "[61 | 280.64] loss=1.25 avg=1.47\n",
            "[62 | 285.14] loss=1.22 avg=1.47\n",
            "[63 | 289.64] loss=1.27 avg=1.46\n",
            "[64 | 294.14] loss=1.28 avg=1.46\n",
            "[65 | 298.64] loss=1.34 avg=1.46\n",
            "[66 | 303.14] loss=1.13 avg=1.45\n",
            "[67 | 307.64] loss=1.23 avg=1.45\n",
            "[68 | 312.14] loss=1.40 avg=1.45\n",
            "[69 | 316.64] loss=1.34 avg=1.44\n",
            "[70 | 321.14] loss=1.33 avg=1.44\n",
            "[71 | 325.64] loss=1.34 avg=1.44\n",
            "[72 | 330.14] loss=1.25 avg=1.44\n",
            "[73 | 334.64] loss=1.19 avg=1.43\n",
            "[74 | 339.14] loss=1.30 avg=1.43\n",
            "[75 | 343.65] loss=1.14 avg=1.42\n",
            "[76 | 348.14] loss=1.10 avg=1.42\n",
            "[77 | 352.64] loss=1.12 avg=1.41\n",
            "[78 | 357.13] loss=1.36 avg=1.41\n",
            "[79 | 361.63] loss=1.22 avg=1.41\n",
            "[80 | 366.13] loss=1.18 avg=1.40\n",
            "[81 | 370.63] loss=1.27 avg=1.40\n",
            "[82 | 375.12] loss=1.21 avg=1.40\n",
            "[83 | 379.61] loss=1.12 avg=1.39\n",
            "[84 | 384.12] loss=1.44 avg=1.39\n",
            "[85 | 388.61] loss=1.28 avg=1.39\n",
            "[86 | 393.12] loss=1.05 avg=1.38\n",
            "[87 | 397.60] loss=1.21 avg=1.38\n",
            "[88 | 402.11] loss=1.25 avg=1.38\n",
            "[89 | 406.61] loss=1.21 avg=1.38\n",
            "[90 | 411.11] loss=1.19 avg=1.37\n",
            "[91 | 415.61] loss=1.24 avg=1.37\n",
            "[92 | 420.11] loss=1.09 avg=1.37\n",
            "[93 | 424.62] loss=1.21 avg=1.36\n",
            "[94 | 429.13] loss=1.33 avg=1.36\n",
            "[95 | 433.63] loss=1.13 avg=1.36\n",
            "[96 | 438.15] loss=1.09 avg=1.36\n",
            "[97 | 442.65] loss=1.31 avg=1.35\n",
            "[98 | 447.15] loss=1.04 avg=1.35\n",
            "[99 | 451.65] loss=1.24 avg=1.35\n",
            "[100 | 456.15] loss=1.15 avg=1.34\n",
            "======== SAMPLE 1 ========\n",
            ", kari padse?\n",
            "24/06/21, 7:18 pm - Kshitij: Pan unhelpful ne\n",
            "24/06/21, 7:18 pm - Kshitij: Ne e pan unhelpful aanu laikho to\n",
            "25/06/21, 5:13 pm - KD: Kairu khabar vaar thai jay vaar\n",
            "25/06/21, 5:13 pm - KD: K\n",
            "25/06/21, 5:13 pm - Kshitij: Haryu?\n",
            "25/06/21, 6:16 pm - KD: üëç\n",
            "26/06/21, 1:01 pm - KD: Aaje banavi che ??\n",
            "26/06/21, 1:01 pm - KD: K\n",
            "26/06/21, 1:01 pm - KD: Ek min thai jase\n",
            "26/06/21, 1:01 pm - Kshitij: Aavyu j j thak thayu\n",
            "26/06/21, 1:01 pm - KD: Na\n",
            "26/06/21, 1:01 pm - KD: A pan banavi che\n",
            "26/06/21, 1:01 pm - KD: A nai\n",
            "26/06/21, 1:01 pm - Kshitij: üòê\n",
            "26/06/21, 1:03 pm - KD: K\n",
            "26/06/21, 0:53 pm - KD: Aaje joie hato\n",
            "26/06/21, 1:02 pm - KD: K\n",
            "26/06/21, 1:03 pm - KD: Aaje kartivo\n",
            "26/06/21, 1:03 pm - KD: K\n",
            "26/06/21, 1:03 pm - KD: A su kai nikhu\n",
            "26/06/21, 1:04 pm - Kshitij: Ha\n",
            "26/06/21, 1:04 pm - Kshitij: Pachi aai ne\n",
            "26/06/21, 1:05 pm - Kshitij: Aapda\n",
            "26/06/21, 1:05 pm - KD: Atyare puchev hati hati\n",
            "28/06/21, 4:41 am - KD: <Media omitted>\n",
            "28/06/21, 4:42 am - Kshitij: https://www.amazon.in.au/Key-Pneumatic-Mechanical-Stab-Bands/dp/B05YX2UQJ1/ref=oh_en_22_04?tag=team_webshop&ex_key=answering_insign&p&qint=quantity%3Banswap&sattr=pdjg3f_pdjgdataq&sr=8-1\n",
            "28/06/21, 4:42 am - Kshitij: Aapde ?\n",
            "28/06/21, 4:42 am - KD: Me aa vadhare j che\n",
            "28/06/21, 4:43 am - KD: Bol\n",
            "28/06/21, 4:43 am - KD: Amto hoo che\n",
            "28/06/21, 4:43 am - KD: Amo chu karyu j che\n",
            "30/06/21, 9:41 am - Kshitij: <Media omitted>\n",
            "30/06/21, 9:43 am - Kshitij: Aatlu karelo\n",
            "30/06/21, 9:43 am - KD: Have to thodi aane leavare madyo\n",
            "30/06/21, 9:43 am - Kshitij: Ha\n",
            "30/06/21, 10:21 am - KD: Pela kevanu aa joia karva che ne?\n",
            "30/06/21, 10:21 am - KD: Khali pan aaare lav par thase che ne?\n",
            "30/06/21, 10:21 am - KD: Aano dej\n",
            "30/06/21, 10:22 am - KD: Pan nathi jevu che\n",
            "30/06/21, 10:22 am - Kshitij: Koi didha aapde che nai aave che ne?\n",
            "30/06/21, 10:22 am - Kshitij: Mare ne?\n",
            "30/06/21, 10:22 am - KD: Hoi\n",
            "30/06/21, 10:22 am - KD: Ha\n",
            "30/06/21, 10:22 am - KD: Etle aavse\n",
            "30/06/21, 10:23 am - KD: Karse ni aavse\n",
            "30/06/21, 10:23 am - KD: Koi th\n",
            "\n",
            "[101 | 482.16] loss=1.13 avg=1.34\n",
            "[102 | 486.68] loss=1.15 avg=1.34\n",
            "[103 | 491.20] loss=1.05 avg=1.33\n",
            "[104 | 495.72] loss=1.22 avg=1.33\n",
            "[105 | 500.24] loss=1.21 avg=1.33\n",
            "[106 | 504.74] loss=1.11 avg=1.33\n",
            "[107 | 509.25] loss=1.05 avg=1.32\n",
            "[108 | 513.77] loss=1.30 avg=1.32\n",
            "[109 | 518.28] loss=1.08 avg=1.32\n",
            "[110 | 522.80] loss=1.02 avg=1.31\n",
            "[111 | 527.31] loss=1.07 avg=1.31\n",
            "[112 | 531.82] loss=1.28 avg=1.31\n",
            "[113 | 536.34] loss=1.15 avg=1.31\n",
            "[114 | 540.84] loss=1.21 avg=1.31\n",
            "[115 | 545.34] loss=1.13 avg=1.30\n",
            "[116 | 549.84] loss=1.12 avg=1.30\n",
            "[117 | 554.36] loss=1.16 avg=1.30\n",
            "[118 | 558.87] loss=1.25 avg=1.30\n",
            "[119 | 563.38] loss=1.15 avg=1.30\n",
            "[120 | 567.88] loss=1.19 avg=1.29\n",
            "[121 | 572.39] loss=1.16 avg=1.29\n",
            "[122 | 576.90] loss=1.32 avg=1.29\n",
            "[123 | 581.40] loss=1.09 avg=1.29\n",
            "[124 | 585.91] loss=1.24 avg=1.29\n",
            "[125 | 590.41] loss=1.17 avg=1.29\n",
            "[126 | 594.92] loss=1.03 avg=1.28\n",
            "[127 | 599.43] loss=1.01 avg=1.28\n",
            "[128 | 603.94] loss=1.27 avg=1.28\n",
            "[129 | 608.44] loss=1.26 avg=1.28\n",
            "[130 | 612.95] loss=1.13 avg=1.28\n",
            "[131 | 617.46] loss=1.23 avg=1.28\n",
            "[132 | 621.96] loss=1.20 avg=1.28\n",
            "[133 | 626.45] loss=1.04 avg=1.27\n",
            "[134 | 630.96] loss=1.12 avg=1.27\n",
            "[135 | 635.47] loss=1.01 avg=1.27\n",
            "[136 | 639.98] loss=1.08 avg=1.26\n",
            "[137 | 644.49] loss=1.04 avg=1.26\n",
            "[138 | 648.99] loss=1.22 avg=1.26\n",
            "[139 | 653.49] loss=1.13 avg=1.26\n",
            "[140 | 658.00] loss=1.06 avg=1.26\n",
            "[141 | 662.50] loss=1.31 avg=1.26\n",
            "[142 | 667.01] loss=1.11 avg=1.26\n",
            "[143 | 671.52] loss=1.24 avg=1.26\n",
            "[144 | 676.02] loss=1.09 avg=1.25\n",
            "[145 | 680.52] loss=1.16 avg=1.25\n",
            "[146 | 685.02] loss=1.05 avg=1.25\n",
            "[147 | 689.52] loss=1.08 avg=1.25\n",
            "[148 | 694.01] loss=1.10 avg=1.25\n",
            "[149 | 698.51] loss=0.98 avg=1.24\n",
            "[150 | 703.02] loss=1.05 avg=1.24\n",
            "[151 | 707.53] loss=1.13 avg=1.24\n",
            "[152 | 712.03] loss=1.14 avg=1.24\n",
            "[153 | 716.53] loss=1.17 avg=1.24\n",
            "[154 | 721.03] loss=1.14 avg=1.23\n",
            "[155 | 725.54] loss=1.13 avg=1.23\n",
            "[156 | 730.04] loss=0.95 avg=1.23\n",
            "[157 | 734.55] loss=1.06 avg=1.23\n",
            "[158 | 739.06] loss=1.14 avg=1.23\n",
            "[159 | 743.55] loss=1.19 avg=1.23\n",
            "[160 | 748.04] loss=1.05 avg=1.22\n",
            "[161 | 752.54] loss=1.06 avg=1.22\n",
            "[162 | 757.05] loss=1.19 avg=1.22\n",
            "[163 | 761.55] loss=1.23 avg=1.22\n",
            "[164 | 766.05] loss=0.96 avg=1.22\n",
            "[165 | 770.55] loss=1.23 avg=1.22\n",
            "[166 | 775.05] loss=1.20 avg=1.22\n",
            "[167 | 779.55] loss=0.98 avg=1.22\n",
            "[168 | 784.05] loss=0.93 avg=1.21\n",
            "[169 | 788.55] loss=1.06 avg=1.21\n",
            "[170 | 793.05] loss=1.21 avg=1.21\n",
            "[171 | 797.54] loss=1.05 avg=1.21\n",
            "[172 | 802.03] loss=1.14 avg=1.21\n",
            "[173 | 806.53] loss=1.08 avg=1.21\n",
            "[174 | 811.03] loss=1.03 avg=1.20\n",
            "[175 | 815.53] loss=1.07 avg=1.20\n",
            "[176 | 820.03] loss=1.04 avg=1.20\n",
            "[177 | 824.54] loss=1.28 avg=1.20\n",
            "[178 | 829.05] loss=1.07 avg=1.20\n",
            "[179 | 833.55] loss=0.97 avg=1.20\n",
            "[180 | 838.05] loss=1.12 avg=1.20\n",
            "[181 | 842.56] loss=0.93 avg=1.19\n",
            "[182 | 847.05] loss=1.15 avg=1.19\n",
            "[183 | 851.56] loss=0.99 avg=1.19\n",
            "[184 | 856.08] loss=1.19 avg=1.19\n",
            "[185 | 860.58] loss=0.96 avg=1.19\n",
            "[186 | 865.09] loss=1.04 avg=1.19\n",
            "[187 | 869.59] loss=0.99 avg=1.18\n",
            "[188 | 874.09] loss=1.11 avg=1.18\n",
            "[189 | 878.59] loss=1.13 avg=1.18\n",
            "[190 | 883.07] loss=1.06 avg=1.18\n",
            "[191 | 887.58] loss=1.03 avg=1.18\n",
            "[192 | 892.08] loss=1.05 avg=1.18\n",
            "[193 | 896.58] loss=0.98 avg=1.17\n",
            "[194 | 901.08] loss=1.04 avg=1.17\n",
            "[195 | 905.58] loss=0.98 avg=1.17\n",
            "[196 | 910.10] loss=0.83 avg=1.17\n",
            "[197 | 914.60] loss=1.00 avg=1.16\n",
            "[198 | 919.10] loss=0.94 avg=1.16\n",
            "[199 | 923.60] loss=1.07 avg=1.16\n",
            "[200 | 928.10] loss=0.96 avg=1.16\n",
            "======== SAMPLE 1 ========\n",
            "\n",
            "10/04/20, 6:24 pm - Kshitij: Ane su che ??\n",
            "10/04/20, 6:24 pm - Kshitij: Ha ej\n",
            "10/04/20, 6:24 pm - KD: ha\n",
            "10/04/20, 6:35 pm - KD: hmm\n",
            "10/04/20, 6:36 pm - Kshitij: aee che\n",
            "10/04/20, 6:36 pm - Kshitij: aapde e jotu j\n",
            "10/04/20, 6:36 pm - Kshitij: <Media omitted>\n",
            "10/04/20, 6:37 pm - KD: <Media omitted>\n",
            "10/04/20, 6:38 pm - Kshitij: Karyu ?\n",
            "10/04/20, 6:39 pm - KD: Biji che\n",
            "10/04/20, 6:39 pm - KD: Ane kya j che\n",
            "10/04/20, 6:39 pm - Kshitij: Ha ha\n",
            "10/04/20, 6:39 pm - Kshitij: Jotu j\n",
            "10/04/20, 6:40 pm - KD: Aane ma jotu j chr\n",
            "11/04/20, 9:36 am - KD: Sar\n",
            "11/04/20, 9:36 am - Kshitij: Bol\n",
            "11/04/20, 9:36 am - Kshitij: <Media omitted>\n",
            "11/04/20, 6:38 pm - KD: <Media omitted>\n",
            "11/04/20, 6:38 pm - Kshitij: Hu vache che to loko\n",
            "11/04/20, 6:38 pm - KD: NoU\n",
            "11/04/20, 6:38 pm - Kshitij: Javanu che ej\n",
            "11/04/20, 6:38 pm - KD: J\n",
            "11/04/20, 6:38 pm - KD: NoU\n",
            "11/04/20, 6:39 pm - Kshitij: ae\n",
            "12/04/20, 9:07 pm - Kshitij: Aa su j joyo? üôÇüòÇ\n",
            "12/04/20, 9:07 pm - Kshitij: E 3 che\n",
            "12/04/20, 9:08 pm - Kshitij: Jigar che üòÇüòÇ\n",
            "12/04/20, 9:07 pm - Kshitij: Fail üòÇüòÇüòÇ\n",
            "12/04/20, 9:08 pm - KD: OwO\n",
            "27/04/20, 7:57 pm - Kshitij: Sar\n",
            "28/04/20, 2:53 pm - KD: Sar\n",
            "28/04/20, 2:53 pm - KD: 3 divas lage che\n",
            "28/04/20, 2:53 pm - KD: Bija biju padse\n",
            "28/04/20, 4:02 pm - Kshitij: Ek kaam kar\n",
            "28/04/20, 4:08 pm - KD: Pachu biju karse\n",
            "28/04/20, 4:08 pm - Kshitij: <Media omitted>\n",
            "29/04/20, 10:30 am - Kshitij: Sar\n",
            "29/04/20, 11:22 am - KD: Hoi\n",
            "29/04/20, 11:22 am - Kshitij: Bija bav jati\n",
            "29/04/20, 11:24 am - KD: üëç\n",
            "29/04/20, 11:24 am - KD: <Media omitted>\n",
            "29/04/20, 11:24 am - KD: Bija na thi karvu\n",
            "29/04/20, 11:24 am - KD: Bija ane k kai nathi nakhvu\n",
            "29/04/20, 11:28 am - Kshitij: <Media omitted>\n",
            "29/04/20, 11:28 am - Kshitij: Su chai\n",
            "29/04/20, 11:28 am - Kshitij: Khali thayu?\n",
            "29/04/20, 11:29 am - Kshitij: ?\n",
            "29/04/20, 6:24 pm - KD: Sar\n",
            "29/04/20, 6:24 pm - KD: Bija joia\n",
            "29/04/20, 6:29 pm - KD: Kk\n",
            "29/04/20, 6:29 pm - KD: Pan 3 divas ma bija joi che\n",
            "29/04/20, 7:21 pm - Kshitij: Sar\n",
            "29/04/20, 5:04 pm - KD: Sar\n",
            "29/04/20, 5:44 pm\n",
            "\n",
            "[201 | 952.78] loss=1.04 avg=1.16\n",
            "[202 | 957.30] loss=0.98 avg=1.16\n",
            "[203 | 961.83] loss=0.98 avg=1.15\n",
            "[204 | 966.34] loss=1.06 avg=1.15\n",
            "[205 | 970.86] loss=1.04 avg=1.15\n",
            "[206 | 975.38] loss=1.02 avg=1.15\n",
            "[207 | 979.89] loss=0.95 avg=1.15\n",
            "[208 | 984.40] loss=0.92 avg=1.14\n",
            "[209 | 988.90] loss=1.21 avg=1.15\n",
            "[210 | 993.41] loss=1.06 avg=1.14\n",
            "[211 | 997.92] loss=0.90 avg=1.14\n",
            "[212 | 1002.42] loss=1.15 avg=1.14\n",
            "[213 | 1006.93] loss=1.01 avg=1.14\n",
            "[214 | 1011.43] loss=1.19 avg=1.14\n",
            "[215 | 1015.94] loss=0.88 avg=1.14\n",
            "[216 | 1020.45] loss=0.87 avg=1.14\n",
            "[217 | 1024.96] loss=1.00 avg=1.13\n",
            "[218 | 1029.47] loss=0.90 avg=1.13\n",
            "[219 | 1033.99] loss=0.93 avg=1.13\n",
            "[220 | 1038.49] loss=0.95 avg=1.13\n",
            "[221 | 1043.00] loss=0.87 avg=1.12\n",
            "[222 | 1047.50] loss=1.00 avg=1.12\n",
            "[223 | 1052.00] loss=0.83 avg=1.12\n",
            "[224 | 1056.50] loss=1.01 avg=1.12\n",
            "[225 | 1061.00] loss=1.18 avg=1.12\n",
            "[226 | 1065.51] loss=0.80 avg=1.12\n",
            "[227 | 1070.01] loss=0.87 avg=1.11\n",
            "[228 | 1074.51] loss=0.88 avg=1.11\n",
            "[229 | 1079.00] loss=0.88 avg=1.11\n",
            "[230 | 1083.50] loss=0.98 avg=1.11\n",
            "[231 | 1088.01] loss=0.82 avg=1.10\n",
            "[232 | 1092.52] loss=0.90 avg=1.10\n",
            "[233 | 1097.03] loss=0.93 avg=1.10\n",
            "[234 | 1101.54] loss=0.96 avg=1.10\n",
            "[235 | 1106.05] loss=1.17 avg=1.10\n",
            "[236 | 1110.55] loss=0.90 avg=1.10\n",
            "[237 | 1115.05] loss=0.87 avg=1.09\n",
            "[238 | 1119.55] loss=0.88 avg=1.09\n",
            "[239 | 1124.06] loss=0.90 avg=1.09\n",
            "[240 | 1128.57] loss=0.90 avg=1.09\n",
            "[241 | 1133.08] loss=0.89 avg=1.08\n",
            "[242 | 1137.58] loss=0.68 avg=1.08\n",
            "[243 | 1142.08] loss=0.86 avg=1.08\n",
            "[244 | 1146.58] loss=0.94 avg=1.08\n",
            "[245 | 1151.08] loss=0.86 avg=1.07\n",
            "[246 | 1155.58] loss=0.83 avg=1.07\n",
            "[247 | 1160.09] loss=0.86 avg=1.07\n",
            "[248 | 1164.61] loss=0.84 avg=1.07\n",
            "[249 | 1169.12] loss=0.86 avg=1.06\n",
            "[250 | 1173.61] loss=0.88 avg=1.06\n",
            "[251 | 1178.11] loss=0.98 avg=1.06\n",
            "[252 | 1182.61] loss=0.77 avg=1.06\n",
            "[253 | 1187.10] loss=0.92 avg=1.06\n",
            "[254 | 1191.61] loss=0.72 avg=1.05\n",
            "[255 | 1196.11] loss=0.83 avg=1.05\n",
            "[256 | 1200.61] loss=0.81 avg=1.05\n",
            "[257 | 1205.12] loss=0.89 avg=1.05\n",
            "[258 | 1209.62] loss=0.85 avg=1.04\n",
            "[259 | 1214.14] loss=0.96 avg=1.04\n",
            "[260 | 1218.66] loss=0.83 avg=1.04\n",
            "[261 | 1223.17] loss=0.81 avg=1.04\n",
            "[262 | 1227.67] loss=0.73 avg=1.04\n",
            "[263 | 1232.18] loss=0.66 avg=1.03\n",
            "[264 | 1236.70] loss=0.81 avg=1.03\n",
            "[265 | 1241.20] loss=0.84 avg=1.03\n",
            "[266 | 1245.71] loss=0.84 avg=1.02\n",
            "[267 | 1250.22] loss=0.88 avg=1.02\n",
            "[268 | 1254.72] loss=0.85 avg=1.02\n",
            "[269 | 1259.22] loss=0.96 avg=1.02\n",
            "[270 | 1263.73] loss=0.82 avg=1.02\n",
            "[271 | 1268.24] loss=0.97 avg=1.02\n",
            "[272 | 1272.78] loss=0.75 avg=1.02\n",
            "[273 | 1277.29] loss=0.83 avg=1.01\n",
            "[274 | 1281.80] loss=0.81 avg=1.01\n",
            "[275 | 1286.31] loss=0.89 avg=1.01\n",
            "[276 | 1290.82] loss=1.03 avg=1.01\n",
            "[277 | 1295.34] loss=0.78 avg=1.01\n",
            "[278 | 1299.84] loss=0.79 avg=1.01\n",
            "[279 | 1304.36] loss=0.84 avg=1.00\n",
            "[280 | 1308.86] loss=0.82 avg=1.00\n",
            "[281 | 1313.36] loss=0.89 avg=1.00\n",
            "[282 | 1317.87] loss=0.92 avg=1.00\n",
            "[283 | 1322.38] loss=0.75 avg=1.00\n",
            "[284 | 1326.88] loss=0.82 avg=0.99\n",
            "[285 | 1331.37] loss=1.02 avg=1.00\n",
            "[286 | 1335.87] loss=0.79 avg=0.99\n",
            "[287 | 1340.37] loss=0.73 avg=0.99\n",
            "[288 | 1344.87] loss=0.80 avg=0.99\n",
            "[289 | 1349.38] loss=0.74 avg=0.99\n",
            "[290 | 1353.89] loss=0.96 avg=0.99\n",
            "[291 | 1358.39] loss=0.68 avg=0.98\n",
            "[292 | 1362.89] loss=0.58 avg=0.98\n",
            "[293 | 1367.39] loss=0.94 avg=0.98\n",
            "[294 | 1371.90] loss=0.89 avg=0.98\n",
            "[295 | 1376.39] loss=0.86 avg=0.98\n",
            "[296 | 1380.89] loss=0.84 avg=0.97\n",
            "[297 | 1385.39] loss=0.82 avg=0.97\n",
            "[298 | 1389.89] loss=0.93 avg=0.97\n",
            "[299 | 1394.38] loss=0.76 avg=0.97\n",
            "[300 | 1398.89] loss=0.85 avg=0.97\n",
            "======== SAMPLE 1 ========\n",
            " am a pachi j nathi\n",
            "19/08/21, 8:18 am - Kshitij: Na re\n",
            "19/08/21, 8:18 am - KD: Pachu j evu lage\n",
            "19/08/21, 8:18 am - KD: üòÜ\n",
            "19/08/21, 8:18 am - KD: Tu kare che ??\n",
            "19/08/21, 8:18 am - Kshitij: To?\n",
            "19/08/21, 8:19 am - KD: Khabar nai\n",
            "19/08/21, 8:19 am - Kshitij: Ha\n",
            "02/09/21, 9:21 am - Kshitij: <Media omitted>\n",
            "02/09/21, 9:21 am - Kshitij: Bol\n",
            "02/09/21, 9:21 am - Kshitij: Aaje jaldi khali\n",
            "02/09/21, 9:21 am - KD: Ha\n",
            "02/09/21, 9:21 am - KD: Aapde mokla pass\n",
            "02/09/21, 9:21 am - Kshitij: Ha ne\n",
            "02/09/21, 9:21 am - KD: Ow\n",
            "02/09/21, 9:21 am - Kshitij: Hu bi aapda jaldi\n",
            "02/09/21, 9:21 am - Kshitij: T5 nu j bargain\n",
            "04/09/21, 9:21 am - KD: You never kai thodi karvanu\n",
            "04/09/21, 9:21 am - KD: <Media omitted>\n",
            "04/09/21, 9:21 am - KD: Saru pan aavyu\n",
            "04/09/21, 9:21 am - KD: Khai lais\n",
            "04/09/21, 10:04 am - KD: Aj kya friend che\n",
            "04/09/21, 10:04 am - Kshitij: Ha\n",
            "04/09/21, 10:04 am - KD: Sed\n",
            "04/09/21, 10:05 am - KD: Tuk tu book change karvanu nathi\n",
            "05/09/21, 10:19 am - Kshitij: Ha\n",
            "05/09/21, 10:19 am - Kshitij: Hu bi aapde ni book change karide\n",
            "05/09/21, 10:19 am - Kshitij: Su thayu hatu\n",
            "05/09/21, 10:19 am - Kshitij: üòÇ\n",
            "05/09/21, 10:19 am - KD: üòÇ\n",
            "05/09/21, 10:19 am - Kshitij: Arre book change karvo che?\n",
            "05/09/21, 10:20 am - Kshitij: Lakhne mane books change kehse\n",
            "05/09/21, 10:20 am - KD: Book baki book shift karvanu\n",
            "05/09/21, 10:20 am - Kshitij: Ha ej\n",
            "05/09/21, 10:20 am - KD: Aavu book baki book change karavi deje\n",
            "05/09/21, 10:20 am - Kshitij: Nai madto dar ne book nai padti\n",
            "05/09/21, 10:20 am - Kshitij: Pan lakhu book change kari daie\n",
            "05/09/21, 10:21 am - Kshitij: Ha\n",
            "05/09/21, 10:21 am - KD: Kai ni didhu\n",
            "05/09/21, 10:21 am - Kshitij: Su tane kai nai?\n",
            "05/09/21, 10:21 am - KD: Na\n",
            "05/09/21, 10:21 am - KD: K\n",
            "05/09/21, 10:21 am - Kshitij: Book vache che\n",
            "05/09/21, 10:21 am - KD: Nai\n",
            "05/09/21, 10:22 am - Kshitij: E chokdi kaam nai kai dav?\n",
            "05/09/21, 10:22 am - KD: Am pan kantado aavde che\n",
            "05/09/21, 10:22 am - Kshitij: Kone khabar\n",
            "05/09/21, 10:23 am - Kshitij: Tya?\n",
            "05/09/21, 10:23 am - KD: Kidhu list change karvani karai\n",
            "05/09/21, 10:27 am - KD: Me aavano nathi la\n",
            "05/09/21, 10:27 am - Kshitij: E ha\n",
            "05/09/21\n",
            "\n",
            "[301 | 1423.28] loss=0.84 avg=0.97\n",
            "[302 | 1427.79] loss=0.71 avg=0.96\n",
            "[303 | 1432.30] loss=0.63 avg=0.96\n",
            "[304 | 1436.82] loss=0.66 avg=0.96\n",
            "[305 | 1441.34] loss=0.89 avg=0.96\n",
            "[306 | 1445.87] loss=0.81 avg=0.96\n",
            "[307 | 1450.38] loss=0.73 avg=0.95\n",
            "[308 | 1454.91] loss=0.81 avg=0.95\n",
            "[309 | 1459.42] loss=0.78 avg=0.95\n",
            "[310 | 1463.93] loss=0.75 avg=0.95\n",
            "[311 | 1468.45] loss=0.65 avg=0.94\n",
            "[312 | 1472.96] loss=0.85 avg=0.94\n",
            "[313 | 1477.48] loss=0.67 avg=0.94\n",
            "[314 | 1481.98] loss=0.70 avg=0.94\n",
            "[315 | 1486.48] loss=0.65 avg=0.93\n",
            "[316 | 1490.99] loss=0.81 avg=0.93\n",
            "[317 | 1495.50] loss=0.85 avg=0.93\n",
            "[318 | 1500.01] loss=0.68 avg=0.93\n",
            "[319 | 1504.52] loss=0.66 avg=0.93\n",
            "[320 | 1509.03] loss=0.77 avg=0.93\n",
            "[321 | 1513.54] loss=0.79 avg=0.92\n",
            "[322 | 1518.07] loss=0.73 avg=0.92\n",
            "[323 | 1522.60] loss=0.71 avg=0.92\n",
            "[324 | 1527.11] loss=0.80 avg=0.92\n",
            "[325 | 1531.62] loss=0.75 avg=0.92\n",
            "[326 | 1536.12] loss=0.65 avg=0.91\n",
            "[327 | 1540.64] loss=0.49 avg=0.91\n",
            "[328 | 1545.16] loss=0.55 avg=0.91\n",
            "[329 | 1549.66] loss=0.83 avg=0.91\n",
            "[330 | 1554.16] loss=0.81 avg=0.90\n",
            "[331 | 1558.66] loss=0.75 avg=0.90\n",
            "[332 | 1563.17] loss=0.77 avg=0.90\n",
            "[333 | 1567.69] loss=0.62 avg=0.90\n",
            "[334 | 1572.19] loss=0.80 avg=0.90\n",
            "[335 | 1576.69] loss=0.59 avg=0.89\n",
            "[336 | 1581.19] loss=0.70 avg=0.89\n",
            "[337 | 1585.70] loss=0.68 avg=0.89\n",
            "[338 | 1590.19] loss=0.78 avg=0.89\n",
            "[339 | 1594.70] loss=0.65 avg=0.89\n",
            "[340 | 1599.21] loss=0.74 avg=0.88\n",
            "[341 | 1603.72] loss=0.69 avg=0.88\n",
            "[342 | 1608.23] loss=0.59 avg=0.88\n",
            "[343 | 1612.73] loss=0.62 avg=0.88\n",
            "[344 | 1617.23] loss=0.59 avg=0.87\n",
            "[345 | 1621.74] loss=0.67 avg=0.87\n",
            "[346 | 1626.23] loss=0.64 avg=0.87\n",
            "[347 | 1630.73] loss=0.81 avg=0.87\n",
            "[348 | 1635.24] loss=0.70 avg=0.87\n",
            "[349 | 1639.74] loss=0.97 avg=0.87\n",
            "[350 | 1644.24] loss=0.75 avg=0.87\n",
            "[351 | 1648.73] loss=0.63 avg=0.86\n",
            "[352 | 1653.24] loss=0.55 avg=0.86\n",
            "[353 | 1657.75] loss=0.68 avg=0.86\n",
            "[354 | 1662.24] loss=0.79 avg=0.86\n",
            "[355 | 1666.74] loss=0.70 avg=0.86\n",
            "[356 | 1671.23] loss=0.59 avg=0.85\n",
            "[357 | 1675.72] loss=0.69 avg=0.85\n",
            "[358 | 1680.24] loss=0.61 avg=0.85\n",
            "[359 | 1684.77] loss=0.64 avg=0.85\n",
            "[360 | 1689.28] loss=0.72 avg=0.85\n",
            "[361 | 1693.78] loss=0.62 avg=0.84\n",
            "[362 | 1698.29] loss=0.63 avg=0.84\n",
            "[363 | 1702.79] loss=0.53 avg=0.84\n",
            "[364 | 1707.30] loss=0.69 avg=0.84\n",
            "[365 | 1711.80] loss=0.70 avg=0.84\n",
            "[366 | 1716.30] loss=0.62 avg=0.83\n",
            "[367 | 1720.82] loss=0.82 avg=0.83\n",
            "[368 | 1725.33] loss=0.80 avg=0.83\n",
            "[369 | 1729.84] loss=0.78 avg=0.83\n",
            "[370 | 1734.35] loss=0.67 avg=0.83\n",
            "[371 | 1738.87] loss=0.59 avg=0.83\n",
            "[372 | 1743.36] loss=0.55 avg=0.83\n",
            "[373 | 1747.86] loss=0.57 avg=0.82\n",
            "[374 | 1752.38] loss=0.51 avg=0.82\n",
            "[375 | 1756.89] loss=0.70 avg=0.82\n",
            "[376 | 1761.40] loss=0.63 avg=0.82\n",
            "[377 | 1765.90] loss=0.71 avg=0.82\n",
            "[378 | 1770.41] loss=0.51 avg=0.81\n",
            "[379 | 1774.92] loss=0.65 avg=0.81\n",
            "[380 | 1779.42] loss=0.56 avg=0.81\n",
            "[381 | 1783.95] loss=0.81 avg=0.81\n",
            "[382 | 1788.46] loss=0.64 avg=0.81\n",
            "[383 | 1792.96] loss=0.46 avg=0.80\n",
            "[384 | 1797.47] loss=0.68 avg=0.80\n",
            "[385 | 1801.98] loss=0.52 avg=0.80\n",
            "[386 | 1806.47] loss=0.67 avg=0.80\n",
            "[387 | 1810.97] loss=0.66 avg=0.80\n",
            "[388 | 1815.48] loss=0.52 avg=0.79\n",
            "[389 | 1820.00] loss=0.51 avg=0.79\n",
            "[390 | 1824.49] loss=0.46 avg=0.79\n",
            "[391 | 1828.98] loss=0.74 avg=0.79\n",
            "[392 | 1833.48] loss=0.62 avg=0.78\n",
            "[393 | 1837.99] loss=0.57 avg=0.78\n",
            "[394 | 1842.49] loss=0.84 avg=0.78\n",
            "[395 | 1847.00] loss=0.70 avg=0.78\n",
            "[396 | 1851.51] loss=0.67 avg=0.78\n",
            "[397 | 1856.00] loss=0.48 avg=0.78\n",
            "[398 | 1860.50] loss=0.69 avg=0.78\n",
            "[399 | 1865.00] loss=0.66 avg=0.78\n",
            "[400 | 1869.51] loss=0.53 avg=0.77\n",
            "======== SAMPLE 1 ========\n",
            "aki ala to jotu pan aapda aavse javanu\n",
            "30/07/21, 8:02 am - KD: Etle\n",
            "30/07/21, 8:02 am - Kshitij: <Media omitted>\n",
            "30/07/21, 8:03 am - Kshitij: Okay üòÇ\n",
            "30/07/21, 8:03 am - Kshitij: Aaj che üòÇ\n",
            "30/07/21, 8:03 am - KD: üëç\n",
            "30/07/21, 8:03 am - KD: Ama cv pan ketli vaachyu\n",
            "30/07/21, 8:03 am - Kshitij: Uper thi vaachyu me pan thodi ochi che ne?\n",
            "30/07/21, 8:03 am - KD: Na tu ani va vaishali\n",
            "30/07/21, 8:04 am - KD: Pchi wifi down che\n",
            "30/07/21, 8:04 am - Kshitij: üòê\n",
            "30/07/21, 8:04 am - KD: To wifi ma problem che\n",
            "30/07/21, 8:04 am - Kshitij: üòÇ\n",
            "30/07/21, 8:05 am - KD: To chale evu\n",
            "30/07/21, 8:06 am - Kshitij: Ha re aavi jase\n",
            "30/07/21, 8:06 am - KD: Nai\n",
            "30/07/21, 8:07 am - KD: üò®\n",
            "30/07/21, 10:13 am - KD: Sar\n",
            "30/07/21, 10:13 am - Kshitij: Bol\n",
            "30/07/21, 10:13 am - KD: Message aavsej\n",
            "30/07/21, 10:13 am - Kshitij: Aavsej\n",
            "30/07/21, 10:13 am - KD: Aav\n",
            "30/07/21, 11:02 am - Kshitij: Aavsej\n",
            "30/07/21, 11:02 am - Kshitij: <Media omitted>\n",
            "30/07/21, 11:02 am - KD: <Media omitted>\n",
            "30/07/21, 11:02 am - Kshitij: Aavsej\n",
            "30/07/21, 11:02 am - KD: <Media omitted>\n",
            "30/07/21, 11:13 am - KD: Sar\n",
            "30/07/21, 11:13 am - Kshitij: Bol\n",
            "30/07/21, 11:13 am - KD: Message aave e haju vapri\n",
            "30/07/21, 11:13 am - KD: 1 min\n",
            "30/07/21, 11:13 am - Kshitij: <Media omitted>\n",
            "30/07/21, 11:13 am - Kshitij: Aavse j\n",
            "30/07/21, 11:13 am - KD: Message aavsej\n",
            "30/07/21, 11:14 am - Kshitij: <Media omitted>\n",
            "30/07/21, 11:14 am - Kshitij: Kem?\n",
            "30/07/21, 11:14 am - KD: Try karu\n",
            "30/07/21, 11:14 am - KD: Kadhi ne 6-7 divas raja\n",
            "30/07/21, 11:15 am - Kshitij: 7-8 divas raah j\n",
            "30/07/21, 11:15 am - KD: Okk\n",
            "30/07/21, 7:28 pm - Kshitij: Sar\n",
            "30/07/21, 7:28 pm - Kshitij: Meet aj ne?\n",
            "30/07/21, 7:28 pm - KD: Ha\n",
            "30/07/21, 7:29 pm - KD: 699\n",
            "30/07/21, 7:29 pm - KD: Thai jase\n",
            "30/07/21, 7:29 pm - KD: 3,4,5\n",
            "30/07/21, 7:29 pm - Kshitij: T5 huto hu karu chu rehvanu haa\n",
            "30/07/21, 7:29 pm - Kshitij: 2-2 chale che\n",
            "30/07/21, 7:29 pm - KD: K\n",
            "30/07/21, 7:30 pm - Kshitij: Mari savarthi chatobot\n",
            "30/07/21, 7:30 pm - KD: Hmm ketlan\n",
            "30/07/21, 7:30 pm - Kshitij: Tb use karelu\n",
            "30/07/21, 7:30 pm - KD: T1 nu friends savarama ??\n",
            "\n",
            "\n",
            "[401 | 1893.94] loss=0.53 avg=0.77\n",
            "[402 | 1898.44] loss=0.53 avg=0.77\n",
            "[403 | 1902.96] loss=0.47 avg=0.77\n",
            "[404 | 1907.48] loss=0.50 avg=0.76\n",
            "[405 | 1911.99] loss=0.69 avg=0.76\n",
            "[406 | 1916.51] loss=0.41 avg=0.76\n",
            "[407 | 1921.02] loss=0.59 avg=0.76\n",
            "[408 | 1925.54] loss=0.50 avg=0.75\n",
            "[409 | 1930.04] loss=0.64 avg=0.75\n",
            "[410 | 1934.55] loss=0.65 avg=0.75\n",
            "[411 | 1939.07] loss=0.69 avg=0.75\n",
            "[412 | 1943.58] loss=0.51 avg=0.75\n",
            "[413 | 1948.09] loss=0.55 avg=0.75\n",
            "[414 | 1952.60] loss=0.55 avg=0.74\n",
            "[415 | 1957.11] loss=0.69 avg=0.74\n",
            "[416 | 1961.61] loss=0.42 avg=0.74\n",
            "[417 | 1966.13] loss=0.57 avg=0.74\n",
            "[418 | 1970.64] loss=0.53 avg=0.74\n",
            "[419 | 1975.15] loss=0.64 avg=0.74\n",
            "[420 | 1979.65] loss=0.43 avg=0.73\n",
            "[421 | 1984.16] loss=0.55 avg=0.73\n",
            "[422 | 1988.66] loss=0.61 avg=0.73\n",
            "[423 | 1993.18] loss=0.46 avg=0.73\n",
            "[424 | 1997.68] loss=0.56 avg=0.73\n",
            "[425 | 2002.18] loss=0.40 avg=0.72\n",
            "[426 | 2006.68] loss=0.64 avg=0.72\n",
            "[427 | 2011.20] loss=0.53 avg=0.72\n",
            "[428 | 2015.69] loss=0.48 avg=0.72\n",
            "[429 | 2020.21] loss=0.60 avg=0.72\n",
            "[430 | 2024.72] loss=0.48 avg=0.71\n",
            "[431 | 2029.23] loss=0.63 avg=0.71\n",
            "[432 | 2033.72] loss=0.35 avg=0.71\n",
            "[433 | 2038.22] loss=0.36 avg=0.71\n",
            "[434 | 2042.73] loss=0.53 avg=0.70\n",
            "[435 | 2047.23] loss=0.55 avg=0.70\n",
            "[436 | 2051.73] loss=0.50 avg=0.70\n",
            "[437 | 2056.24] loss=0.59 avg=0.70\n",
            "[438 | 2060.73] loss=0.56 avg=0.70\n",
            "[439 | 2065.23] loss=0.56 avg=0.70\n",
            "[440 | 2069.73] loss=0.53 avg=0.69\n",
            "[441 | 2074.24] loss=0.59 avg=0.69\n",
            "[442 | 2078.75] loss=0.53 avg=0.69\n",
            "[443 | 2083.25] loss=0.65 avg=0.69\n",
            "[444 | 2087.74] loss=0.60 avg=0.69\n",
            "[445 | 2092.24] loss=0.43 avg=0.69\n",
            "[446 | 2096.75] loss=0.47 avg=0.69\n",
            "[447 | 2101.24] loss=0.51 avg=0.68\n",
            "[448 | 2105.74] loss=0.60 avg=0.68\n",
            "[449 | 2110.24] loss=0.38 avg=0.68\n",
            "[450 | 2114.73] loss=0.41 avg=0.68\n",
            "[451 | 2119.23] loss=0.57 avg=0.68\n",
            "[452 | 2123.73] loss=0.49 avg=0.67\n",
            "[453 | 2128.24] loss=0.49 avg=0.67\n",
            "[454 | 2132.74] loss=0.38 avg=0.67\n",
            "[455 | 2137.24] loss=0.56 avg=0.67\n",
            "[456 | 2141.74] loss=0.43 avg=0.67\n",
            "[457 | 2146.25] loss=0.39 avg=0.66\n",
            "[458 | 2150.75] loss=0.44 avg=0.66\n",
            "[459 | 2155.25] loss=0.46 avg=0.66\n",
            "[460 | 2159.75] loss=0.54 avg=0.66\n",
            "[461 | 2164.26] loss=0.47 avg=0.66\n",
            "[462 | 2168.77] loss=0.26 avg=0.65\n",
            "[463 | 2173.28] loss=0.40 avg=0.65\n",
            "[464 | 2177.78] loss=0.43 avg=0.65\n",
            "[465 | 2182.30] loss=0.38 avg=0.64\n",
            "[466 | 2186.80] loss=0.45 avg=0.64\n",
            "[467 | 2191.30] loss=0.49 avg=0.64\n",
            "[468 | 2195.81] loss=0.31 avg=0.64\n",
            "[469 | 2200.32] loss=0.44 avg=0.64\n",
            "[470 | 2204.82] loss=0.32 avg=0.63\n",
            "[471 | 2209.32] loss=0.63 avg=0.63\n",
            "[472 | 2213.84] loss=0.42 avg=0.63\n",
            "[473 | 2218.35] loss=0.39 avg=0.63\n",
            "[474 | 2222.87] loss=0.38 avg=0.63\n",
            "[475 | 2227.38] loss=0.41 avg=0.62\n",
            "[476 | 2231.90] loss=0.33 avg=0.62\n",
            "[477 | 2236.43] loss=0.29 avg=0.62\n",
            "[478 | 2240.97] loss=0.52 avg=0.62\n",
            "[479 | 2245.47] loss=0.44 avg=0.61\n",
            "[480 | 2249.99] loss=0.36 avg=0.61\n",
            "[481 | 2254.50] loss=0.41 avg=0.61\n",
            "[482 | 2259.01] loss=0.36 avg=0.61\n",
            "[483 | 2263.52] loss=0.38 avg=0.60\n",
            "[484 | 2268.04] loss=0.45 avg=0.60\n",
            "[485 | 2272.54] loss=0.32 avg=0.60\n",
            "[486 | 2277.05] loss=0.32 avg=0.60\n",
            "[487 | 2281.55] loss=0.31 avg=0.59\n",
            "[488 | 2286.05] loss=0.34 avg=0.59\n",
            "[489 | 2290.56] loss=0.43 avg=0.59\n",
            "[490 | 2295.07] loss=0.45 avg=0.59\n",
            "[491 | 2299.59] loss=0.36 avg=0.59\n",
            "[492 | 2304.10] loss=0.40 avg=0.58\n",
            "[493 | 2308.60] loss=0.56 avg=0.58\n",
            "[494 | 2313.10] loss=0.46 avg=0.58\n",
            "[495 | 2317.62] loss=0.35 avg=0.58\n",
            "[496 | 2322.13] loss=0.44 avg=0.58\n",
            "[497 | 2326.64] loss=0.48 avg=0.58\n",
            "[498 | 2331.16] loss=0.42 avg=0.58\n",
            "[499 | 2335.67] loss=0.31 avg=0.57\n",
            "[500 | 2340.18] loss=0.28 avg=0.57\n",
            "======== SAMPLE 1 ========\n",
            "ij: Na\n",
            "29/10/21, 10:13 pm - Kshitij: Me lampahan ne thi test nathi kase\n",
            "29/10/21, 10:13 pm - Kshitij: üòê\n",
            "29/10/21, 10:13 pm - Kshitij: Thai gayu\n",
            "29/10/21, 10:13 pm - KD: Chhod have nathi kai\n",
            "29/10/21, 10:13 pm - Kshitij: üòêü§Ø\n",
            "29/10/21, 10:14 pm - Kshitij: Jhaam hamna thi\n",
            "29/10/21, 10:14 pm - KD: Pero\n",
            "29/10/21, 10:14 pm - Kshitij: NoU\n",
            "29/10/21, 10:14 pm - KD: üôÑ\n",
            "29/10/21, 10:14 pm - Kshitij: Joyu jase\n",
            "29/10/21, 10:15 pm - Kshitij: Maibi tha\n",
            "29/10/21, 10:15 pm - Kshitij: <Media omitted>\n",
            "29/10/21, 10:15 pm - KD: Thodo ne koi nana mid\n",
            "29/10/21, 10:15 pm - KD: Ketla thaya\n",
            "29/10/21, 11:06 pm - Kshitij: <Media omitted>\n",
            "29/10/21, 11:06 pm - Kshitij: Aakhi rat vadhi laage che\n",
            "29/10/21, 11:07 pm - Kshitij: Jase\n",
            "29/10/21, 11:07 pm - Kshitij: üòê\n",
            "29/10/21, 11:07 pm - KD: üòí\n",
            "29/10/21, 11:07 pm - Kshitij: E gt fake email par\n",
            "29/10/21, 11:07 pm - Kshitij: Gt fake social network par\n",
            "29/10/21, 11:08 pm - KD: Aave\n",
            "29/10/21, 11:09 pm - Kshitij: Baaki gt fakeru che aav\n",
            "29/10/21, 11:09 pm - KD: Aavto nathi\n",
            "29/10/21, 11:09 pm - Kshitij: üòÇ\n",
            "29/10/21, 11:09 pm - KD: Meet ne pase mail ni nai\n",
            "29/10/21, 11:09 pm - Kshitij: Ha\n",
            "29/10/21, 11:09 pm - Kshitij: üòÇüòÇ\n",
            "29/10/21, 11:10 pm - KD: Phone ma nathi aapde\n",
            "29/10/21, 11:10 pm - Kshitij: Ame to 15$ thaiüòÇüòÇ\n",
            "29/10/21, 11:10 pm - KD: Bov mota 4 divas net hamna\n",
            "29/10/21, 11:10 pm - Kshitij: Arre etle net bill gt family ma gaya\n",
            "29/10/21, 11:10 pm - KD: Aave etle net charge kharab na thay\n",
            "29/10/21, 11:10 pm - KD: Atle 4 jana vadhare tare kais\n",
            "29/10/21, 11:11 pm - Kshitij: Mihir thase rehmane\n",
            "29/10/21, 11:11 pm - Kshitij: Tare tu bhul thase rehmane hamna koi family maang more\n",
            "29/10/21, 11:11 pm - KD: Su kare che\n",
            "29/10/21, 11:11 pm - KD: Marama 2 jana vadhare j marama mihir\n",
            "29/10/21, 11:11 pm - KD: Marama ghana j nathi\n",
            "29/10/21, 11:12 pm - Kshitij: E banav j\n",
            "29/10/21, 11:12 pm - Kshitij: Ghias ma chale\n",
            "29/10/21, 11:12 pm - KD: Chale hoy to passpi diy\n",
            "29/10/21, 11:12 pm - Kshitij: üòÇ\n",
            "29/10/21, 11:12 pm - Kshitij: Arre etle kai thase option thai che\n",
            "29/10/21, 11:12 pm - Kshitij: üòÇ\n",
            "29/10/21, 11:13 pm - KD: OwO to pan nathi thay\n",
            "29/10/21, 11:13 pm - Kshitij: Ek min\n",
            "29/10/21, 11:13 pm - Kshitij:\n",
            "\n",
            "[501 | 2364.80] loss=0.41 avg=0.57\n",
            "[502 | 2369.33] loss=0.49 avg=0.57\n",
            "[503 | 2373.85] loss=0.30 avg=0.57\n",
            "[504 | 2378.37] loss=0.26 avg=0.56\n",
            "[505 | 2382.89] loss=0.33 avg=0.56\n",
            "[506 | 2387.40] loss=0.27 avg=0.56\n",
            "[507 | 2391.91] loss=0.52 avg=0.56\n",
            "[508 | 2396.42] loss=0.23 avg=0.55\n",
            "[509 | 2400.94] loss=0.28 avg=0.55\n",
            "[510 | 2405.45] loss=0.36 avg=0.55\n",
            "[511 | 2409.95] loss=0.39 avg=0.55\n",
            "[512 | 2414.46] loss=0.37 avg=0.55\n",
            "[513 | 2418.97] loss=0.38 avg=0.54\n",
            "[514 | 2423.49] loss=0.41 avg=0.54\n",
            "[515 | 2428.00] loss=0.36 avg=0.54\n",
            "[516 | 2432.52] loss=0.34 avg=0.54\n",
            "[517 | 2437.04] loss=0.34 avg=0.54\n",
            "[518 | 2441.56] loss=0.33 avg=0.53\n",
            "[519 | 2446.08] loss=0.25 avg=0.53\n",
            "[520 | 2450.59] loss=0.31 avg=0.53\n",
            "[521 | 2455.11] loss=0.27 avg=0.53\n",
            "[522 | 2459.63] loss=0.29 avg=0.52\n",
            "[523 | 2464.14] loss=0.44 avg=0.52\n",
            "[524 | 2468.66] loss=0.43 avg=0.52\n",
            "[525 | 2473.18] loss=0.31 avg=0.52\n",
            "[526 | 2477.69] loss=0.45 avg=0.52\n",
            "[527 | 2482.22] loss=0.29 avg=0.52\n",
            "[528 | 2486.74] loss=0.36 avg=0.52\n",
            "[529 | 2491.26] loss=0.38 avg=0.51\n",
            "[530 | 2495.79] loss=0.33 avg=0.51\n",
            "[531 | 2500.29] loss=0.37 avg=0.51\n",
            "[532 | 2504.82] loss=0.36 avg=0.51\n",
            "[533 | 2509.34] loss=0.43 avg=0.51\n",
            "[534 | 2513.85] loss=0.30 avg=0.51\n",
            "[535 | 2518.36] loss=0.30 avg=0.51\n",
            "[536 | 2522.88] loss=0.24 avg=0.50\n",
            "[537 | 2527.41] loss=0.35 avg=0.50\n",
            "[538 | 2531.94] loss=0.30 avg=0.50\n",
            "[539 | 2536.45] loss=0.39 avg=0.50\n",
            "[540 | 2540.97] loss=0.32 avg=0.50\n",
            "[541 | 2545.48] loss=0.42 avg=0.50\n",
            "[542 | 2550.01] loss=0.32 avg=0.49\n",
            "[543 | 2554.52] loss=0.53 avg=0.49\n",
            "[544 | 2559.05] loss=0.35 avg=0.49\n",
            "[545 | 2563.56] loss=0.22 avg=0.49\n",
            "[546 | 2568.07] loss=0.27 avg=0.49\n",
            "[547 | 2572.60] loss=0.42 avg=0.49\n",
            "[548 | 2577.11] loss=0.39 avg=0.49\n",
            "[549 | 2581.64] loss=0.39 avg=0.48\n",
            "[550 | 2586.15] loss=0.35 avg=0.48\n",
            "[551 | 2590.67] loss=0.37 avg=0.48\n",
            "[552 | 2595.18] loss=0.43 avg=0.48\n",
            "[553 | 2599.70] loss=0.30 avg=0.48\n",
            "[554 | 2604.22] loss=0.33 avg=0.48\n",
            "[555 | 2608.75] loss=0.27 avg=0.48\n",
            "[556 | 2613.27] loss=0.21 avg=0.47\n",
            "[557 | 2617.78] loss=0.37 avg=0.47\n",
            "[558 | 2622.30] loss=0.29 avg=0.47\n",
            "[559 | 2626.82] loss=0.27 avg=0.47\n",
            "[560 | 2631.33] loss=0.33 avg=0.47\n",
            "[561 | 2635.85] loss=0.25 avg=0.47\n",
            "[562 | 2640.37] loss=0.33 avg=0.46\n",
            "[563 | 2644.89] loss=0.30 avg=0.46\n",
            "[564 | 2649.40] loss=0.34 avg=0.46\n",
            "[565 | 2653.91] loss=0.22 avg=0.46\n",
            "[566 | 2658.42] loss=0.26 avg=0.46\n",
            "[567 | 2662.91] loss=0.25 avg=0.45\n",
            "[568 | 2667.42] loss=0.35 avg=0.45\n",
            "[569 | 2671.91] loss=0.19 avg=0.45\n",
            "[570 | 2676.43] loss=0.28 avg=0.45\n",
            "[571 | 2680.94] loss=0.20 avg=0.45\n",
            "[572 | 2685.46] loss=0.34 avg=0.45\n",
            "[573 | 2689.98] loss=0.22 avg=0.44\n",
            "[574 | 2694.50] loss=0.39 avg=0.44\n",
            "[575 | 2699.01] loss=0.27 avg=0.44\n",
            "[576 | 2703.54] loss=0.32 avg=0.44\n",
            "[577 | 2708.05] loss=0.29 avg=0.44\n",
            "[578 | 2712.57] loss=0.18 avg=0.44\n",
            "[579 | 2717.09] loss=0.30 avg=0.43\n",
            "[580 | 2721.60] loss=0.31 avg=0.43\n",
            "[581 | 2726.13] loss=0.32 avg=0.43\n",
            "[582 | 2730.65] loss=0.21 avg=0.43\n",
            "[583 | 2735.17] loss=0.31 avg=0.43\n",
            "interrupted\n",
            "Saving checkpoint/run1/model-583\n"
          ]
        }
      ],
      "source": [
        "gpt2.finetune(sess, 'chat.txt', model_name=model_name, steps=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIPn1kPt9M_O",
        "outputId": "eedac22f-e58c-446c-bc98-aaa04af639e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/ (stored 0%)\n",
            "  adding: content/.config/ (stored 0%)\n",
            "  adding: content/.config/.last_survey_prompt.yaml (stored 0%)\n",
            "  adding: content/.config/.last_update_check.json (deflated 22%)\n",
            "  adding: content/.config/configurations/ (stored 0%)\n",
            "  adding: content/.config/configurations/config_default (deflated 15%)\n",
            "  adding: content/.config/config_sentinel (stored 0%)\n",
            "  adding: content/.config/logs/ (stored 0%)\n",
            "  adding: content/.config/logs/2022.03.23/ (stored 0%)\n",
            "  adding: content/.config/logs/2022.03.23/14.22.11.024461.log (deflated 54%)\n",
            "  adding: content/.config/logs/2022.03.23/14.22.10.115472.log (deflated 55%)\n",
            "  adding: content/.config/logs/2022.03.23/14.20.51.700340.log (deflated 90%)\n",
            "  adding: content/.config/logs/2022.03.23/14.21.37.874736.log (deflated 86%)\n",
            "  adding: content/.config/logs/2022.03.23/14.21.47.434153.log (deflated 53%)\n",
            "  adding: content/.config/logs/2022.03.23/14.21.15.158122.log (deflated 53%)\n",
            "  adding: content/.config/.last_opt_in_prompt.yaml (stored 0%)\n",
            "  adding: content/.config/.metricsUUID (stored 0%)\n",
            "  adding: content/.config/.feature_flags_config.yaml (deflated 23%)\n",
            "  adding: content/.config/active_config (stored 0%)\n",
            "  adding: content/.config/gce (stored 0%)\n",
            "  adding: content/models/ (stored 0%)\n",
            "  adding: content/models/124M/ (stored 0%)\n",
            "  adding: content/models/124M/vocab.bpe (deflated 53%)\n",
            "  adding: content/models/124M/encoder.json (deflated 67%)\n",
            "  adding: content/models/124M/checkpoint (deflated 42%)\n",
            "  adding: content/models/124M/model.ckpt.meta (deflated 91%)\n",
            "  adding: content/models/124M/hparams.json (deflated 28%)\n",
            "  adding: content/models/124M/model.ckpt.index (deflated 62%)\n",
            "  adding: content/models/124M/model.ckpt.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/checkpoint/ (stored 0%)\n",
            "  adding: content/checkpoint/run1/ (stored 0%)\n",
            "  adding: content/checkpoint/run1/model-583.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/checkpoint/run1/events.out.tfevents.1649264878.19f3672c9f48 (deflated 59%)\n",
            "  adding: content/checkpoint/run1/vocab.bpe (deflated 53%)\n",
            "  adding: content/checkpoint/run1/model-583.meta (deflated 92%)\n",
            "  adding: content/checkpoint/run1/encoder.json (deflated 67%)\n",
            "  adding: content/checkpoint/run1/checkpoint (deflated 40%)\n",
            "  adding: content/checkpoint/run1/model-583.index (deflated 62%)\n",
            "  adding: content/checkpoint/run1/counter (stored 0%)\n",
            "  adding: content/checkpoint/run1/hparams.json (deflated 28%)\n",
            "  adding: content/samples/ (stored 0%)\n",
            "  adding: content/samples/run1/ (stored 0%)\n",
            "  adding: content/samples/run1/samples-501 (deflated 71%)\n",
            "  adding: content/samples/run1/samples-401 (deflated 72%)\n",
            "  adding: content/samples/run1/samples-201 (deflated 73%)\n",
            "  adding: content/samples/run1/samples-101 (deflated 64%)\n",
            "  adding: content/samples/run1/samples-301 (deflated 72%)\n",
            "  adding: content/chat.txt (deflated 76%)\n",
            "  adding: content/sample_data/ (stored 0%)\n",
            "  adding: content/sample_data/anscombe.json (deflated 83%)\n",
            "  adding: content/sample_data/README.md (deflated 42%)\n",
            "  adding: content/sample_data/mnist_test.csv (deflated 88%)\n",
            "  adding: content/sample_data/california_housing_test.csv (deflated 76%)\n",
            "  adding: content/sample_data/mnist_train_small.csv (deflated 88%)\n",
            "  adding: content/sample_data/california_housing_train.csv (deflated 79%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /model.zip /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RuOKt1QLAGm4",
        "outputId": "b9b8a35a-0e96-494d-ac7d-633d87a7fd40"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-04265ad62ce7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/model.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    187\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: /content/model.zip"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/model.zip\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "gpt2 chat.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}